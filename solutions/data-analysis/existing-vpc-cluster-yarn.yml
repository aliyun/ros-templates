ROSTemplateFormatVersion: '2015-09-01'
Description:
  zh-cn: 在现有VPC基础上，通过ROS模板部署Hadoop YARN集群，包含管理节点（绑定EIP）和自动伸缩控制的计算节点，配置Java 1.8.0和Hadoop
    2.7.7，确保8088和50070端口访问安全。
  en: On top of the existing VPC infrastructure, deploy a Hadoop YARN cluster via
    ROS (Resource Orchestration Service) templates, comprising management nodes (with
    EIPs attached) and compute nodes under auto-scaling control. The cluster is configured
    with Java 1.8.0 and Hadoop 2.7.7, ensuring secure access to ports 8088 and 50070.
Parameters:
  VpcId:
    Type: String
    Label:
      en: Existing VPC Instance ID
      zh-cn: 现有VPC的实例ID
    Description:
      en: Please search the ID starting with (vpc-xxx)from console-Virtual Private
        Cloud
      zh-cn: 控制台-VPC-专有网络下查询
    AssociationProperty: ALIYUN::ECS::VPC::VPCId
  VSwitchZoneId:
    Type: String
    Label:
      en: VSwitch Zone ID
      zh-cn: 交换机可用区
    Description:
      en: New Switch Availability Zone ID
      zh-cn: 新建交换机Switch的可用区ID
    AssociationProperty: ALIYUN::ECS::Instance::ZoneId
  VSwitchId:
    Type: String
    Label:
      en: VSwitch ID
      zh-cn: 网络交换机ID
    Description:
      en: Please search the business VSwitch ID starting with(vsw-xxx)from console-Virtual
        Private Cloud-VSwitches
      zh-cn: 现有业务网络交换机的实例ID,控制台-VPC-专有网络-交换机下查询
    AssociationProperty: ALIYUN::ECS::VSwitch::VSwitchId
    AssociationPropertyMetadata:
      VpcId: VpcId
  SecurityGroupId:
    Type: String
    Label:
      en: Business Security Group ID
      zh-cn: 业务安全组ID
    Description:
      en: Please search the business security group ID starting with(sg-xxx)from console-ECS-Network
        & Security
      zh-cn: 现有业务安全组的实例ID,控制台-ECS-网络与安全-安全组下查询
    AssociationProperty: ALIYUN::ECS::SecurityGroup::SecurityGroupId
    AssociationPropertyMetadata:
      VpcId: VpcId
  InstanceType:
    Type: String
    Label:
      en: Instance Type
      zh-cn: 实例规格
    Description:
      en: <font color='blue'><b>1.Before selecting the model please confirm that the
        current available zone under the model is in stock, some models need to be
        reported in advance</b></font>]<br><font color='blue'><b>2.List of optional
        models</font>]<br></b></font>[ecs.c5.large <font color='green'>2vCPU 4GiB
        Intranet bandwidth1Gbps In-grid sending and receiving packages30MillionPPSS</font>]<br></b>[ecs.c5.xlarge
        <font color='green'>4vCPU 8GiB Intranet bandwidth1.5Gbps In-grid sending and
        receiving packages50MillionPPS</font>]<br></b>[ecs.c5.2xlarge <font color='green'>8vCPU
        16GiB Intranet bandwidth2.5Gbps In-grid sending and receiving packages80MillionPPS</font>]
      zh-cn: <font color='blue'><b>1.选择机型前请先确认当前可用区下该机型是否有货，部分机型需要提前报备</b></font><br><font
        color='blue'><b>2.可选机型列表</font><br></b></font>[ecs.c5.large <font color='green'>2vCPU
        4GiB 内网带宽1Gbps 内网收发包30万PPS</font>]<br></b>[ecs.c5.xlarge <font color='green'>4vCPU
        8GiB 内网带宽1.5Gbps 内网收发包50万PPS</font>]<br></b>[ecs.c5.2xlarge <font color='green'>8vCPU
        16GiB 内网带宽2.5Gbps 内网收发包80万PPS</font>]
    AssociationProperty: ALIYUN::ECS::Instance::InstanceType
    AssociationPropertyMetadata:
      ZoneId: VSwitchZoneId
  InstancePassword:
    Type: String
    Label:
      en: Instance Password
      zh-cn: 实例密码
    Description:
      en: Server login password, Length 8-30, must contain three(Capital letters,
        lowercase letters, numbers, ()`~!@#$%^&*_-+=|{}[]:;'<>,.?/ Special symbol
        in)
      zh-cn: 服务器登录密码,长度8-30，必须包含三项（大写字母、小写字母、数字、 ()`~!@#$%^&*_-+=|{}[]:;'<>,.?/ 中的特殊符号）
    ConstraintDescription:
      en: Length 8-30, must contain three(Capital letters, lowercase letters, numbers,
        ()`~!@#$%^&*_-+=|{}[]:;'<>,.?/ Special symbol in).
      zh-cn: 长度8-30，必须包含三项（大写字母、小写字母、数字、 ()`~!@#$%^&*_-+=|{}[]:;'<>,.?/ 中的特殊符号）。
    AllowedPattern: '[0-9A-Za-z\_\-\&:;''<>,=%`~!@#\(\)\$\^\*\+\|\{\}\[\]\.\?\/]+$'
    MinLength: 8
    MaxLength: 30
    NoEcho: true
  BindWidth:
    Type: Number
    Label:
      en: Public IP Bandwidth
      zh-cn: 公网IP带宽值
    Description:
      en: 'Public network IP bandwidth，unit: Mbps'
      zh-cn: 公网IP带宽值，单位：Mbps
    Default: 5
    MinValue: 1
    MaxValue: 100
  DiskCategory:
    Type: String
    Label:
      en: Disk Type
      zh-cn: 磁盘类型
    Description:
      en: '<font color=''blue''><b>Optional values:</b></font><br>[cloud_efficiency:
        <font color=''green''>Efficient Cloud Disk</font>]<br>[cloud_ssd: <font color=''green''>SSD
        Cloud Disk</font>]<br>[cloud_essd: <font color=''green''>ESSD Cloud Disk</font>]<br>[cloud:
        <font color=''green''>Cloud Disk</font>]<br>[ephemeral_ssd: <font color=''green''>Local
        SSD Cloud Disk</font>]'
      zh-cn: '<font color=''blue''><b>可选值：</b></font><br>[cloud_efficiency: <font
        color=''green''>高效云盘</font>]<br>[cloud_ssd: <font color=''green''>SSD云盘</font>]<br>[cloud_essd:
        <font color=''green''>ESSD云盘</font>]<br>[cloud: <font color=''green''>普通云盘</font>]<br>[ephemeral_ssd:
        <font color=''green''>本地SSD盘</font>]'
    Default: cloud_efficiency
    AllowedValues:
    - cloud_efficiency
    - cloud_ssd
    - cloud
    - cloud_essd
    - ephemeral_ssd
  DiskSize:
    Type: Number
    Label:
      en: System Disk Space
      zh-cn: 系统盘空间
    Description:
      en: ''
      zh-cn: 实例系统盘大小，单位为GiB。取值范围：20~32768
    Default: 40
    MinValue: 20
    MaxValue: 2048
  Amount:
    Type: Number
    Label:
      en: Instance Amount
      zh-cn: 实例数量
    Description:
      en: 'ECS Instance Amount, Allowed value: 3~10'
      zh-cn: 购买实例数量，允许值：3~10
    Default: 3
    MinValue: 3
    MaxValue: 10
  InstanceImageId:
    Type: String
    Label:
      en: Image ID
      zh-cn: 镜像ID
    Description:
      en: Image ID，See detail：<b><a href='https://www.alibabacloud.com/help/doc-detail/112977.html'
        target='_blank'><font color='blue'>Find the mirror</font></a></b>
      zh-cn: 镜像ID, 详见：<b><a href='https://help.aliyun.com/document_detail/112977.html'
        target='_blank'><font color='blue'>查找镜像</font></a></b>
    Default: centos_7
Resources:
  RamRole:
    Type: ALIYUN::RAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - oos.aliyuncs.com
        Version: '1'
      Policies:
      - PolicyDocument:
          Statement:
          - Action:
            - ecs:*
            Effect: Allow
            Resource:
            - '*'
          - Action:
            - vpc:DescribeVpcs
            - vpc:DescribeVSwitches
            Effect: Allow
            Resource:
            - '*'
          - Action:
            - ess:CompleteLifecycleAction
            Effect: Allow
            Resource:
            - '*'
          Version: '1'
        PolicyName:
          Fn::Join:
          - ''
          - - ros-StackId-
            - Ref: ALIYUN::StackId
      RoleName:
        Fn::Join:
        - ''
        - - ros-StackId-
          - Ref: ALIYUN::StackId
    Metadata:
      ALIYUN::ROS::Designer:
        id: c40eb24b-0042-4ad8-b85c-b6155fa52238
  OOSTemplateIn:
    Type: ALIYUN::OOS::Template
    Properties:
      Content:
        Fn::Join:
        - ''
        - - '{"FormatVersion": "OOS-2019-06-01","Parameters": {"regionId": {"Type":
            "String","Default": "'
          - Ref: ALIYUN::Region
          - '"},"instanceIds": {"Type": "List","Default": ["${instanceId}"]},"lifecycleHookId":
            {"Type": "String","Default": "${lifecycleHookId}"},"lifecycleActionToken":
            {"Type": "String","Default": "${lifecycleActionToken}"}},"RamRole": "'
          - Fn::GetAtt:
            - RamRole
            - RoleName
          - '","Tasks": [{"Name": "runCommand","Action": "ACS::ECS::RunCommand","OnError":
            "CompleteLifecycleActionForAbandon","OnSuccess": "CompleteLifecycleActionForContinue","Properties":
            {"regionId": "{{ regionId }}","commandContent": "'
          - 'cd /software && bash rm_node.sh '
          - Ref: Amount
          - ' && sleep 60'
          - '","instanceId": "{{ ACS::TaskLoopItem }}","commandType": "RunShellScript"},
            "Loop": {"RateControl": {"Mode":"Concurrency","MaxErrors":0,"Concurrency":10},"Items":
            "{{ instanceIds }}","Outputs": {"commandOutputs": {"AggregateType": "Fn::ListJoin","AggregateField":
            "commandOutput"}}},"Outputs": {"commandOutput": {"Type": "String","ValueSelector":
            "invocationOutput"}}}, {"Name": "CompleteLifecycleActionForContinue","Action":
            "ACS::ExecuteAPI","OnSuccess": "ACS::END","Properties": {"Service": "ESS","API":
            "CompleteLifecycleAction","Parameters": {"RegionId": "{{ regionId }}","LifecycleHookId":
            "{{ lifecycleHookId }}","LifecycleActionToken": "{{ lifecycleActionToken
            }}"}}}, {"Name": "CompleteLifecycleActionForAbandon","Action": "ACS::ExecuteAPI","Properties":
            {"Service": "ESS","API": "CompleteLifecycleAction","Parameters": {"RegionId":
            "{{ regionId }}","LifecycleHookId": "{{ lifecycleHookId }}","LifecycleActionToken":
            "{{ lifecycleActionToken }}","LifecycleActionResult": "ABANDON"}}}]}'
      TemplateName:
        Fn::Join:
        - ''
        - - ros-StackId-
          - Ref: ALIYUN::StackId
    DependsOn:
    - RamRole
    Metadata:
      ALIYUN::ROS::Designer:
        id: f38f57e5-4fad-404f-9550-45331dca1d60
  EcsInstanceGroupMaster:
    Type: ALIYUN::ECS::InstanceGroup
    Properties:
      ZoneId:
        Ref: VSwitchZoneId
      VpcId:
        Ref: VpcId
      VSwitchId:
        Ref: VSwitchId
      SecurityGroupId:
        Ref: SecurityGroupId
      ImageId:
        Ref: InstanceImageId
      AllocatePublicIP: false
      HostName:
        Fn::Join:
        - ''
        - - YARN
          - -[0,3]
      InstanceChargeType: PostPaid
      InstanceName:
        Fn::Join:
        - ''
        - - YARN
          - -[0,3]
      InstanceType:
        Ref: InstanceType
      InternetMaxBandwidthIn:
        Ref: BindWidth
      InternetMaxBandwidthOut:
        Ref: BindWidth
      IoOptimized: optimized
      MaxAmount: 1
      Password:
        Ref: InstancePassword
      SystemDiskCategory:
        Ref: DiskCategory
      UserData:
        Fn::Replace:
        - ros-notify:
            Fn::GetAtt:
            - RosWaitConditionMasterHandle
            - CurlCli
        - Fn::Join:
          - ''
          - - "#!/bin/sh \n"
            - PASSWORD="
            - Ref: InstancePassword
            - "\" \n"
            - NODE_COUNT=
            - Ref: Amount
            - " \n"
            - ROS_NOTIFY="
            - Fn::GetAtt:
              - RosWaitConditionClusterHandle
              - CurlCli
            - "\" \n"
            - "sleep 10 \n"
            - "set -e \n"
            - "OSS_NAME=\"ros-template-resources\" \n"
            - "OSS_REGION=\"cn-beijing\" \n"
            - "ENDPOINT=\".aliyuncs.com\" \n"
            - "OOS_JDK_FOLDER=\"JDK\" \n"
            - "JDK_RPM=\"jdk-8u251-linux-i586.rpm\" \n"
            - "OOS_HADOOP_FOLDER=\"Hadoop\" \n"
            - "HADOOP_PACKAGE=\"hadoop-2.7.7.tar.gz\" \n"
            - "ENV_DIR=\"/software\" \n"
            - "BASH_PATH=\"/etc/profile\" \n"
            - "RESOURCE_DIR=\"${ENV_DIR}/resources\" \n"
            - "HADOOP_HOME=\"${ENV_DIR}/hadoop\" \n"
            - "HOST_IP=$(ifconfig eth0 | awk '/inet /{print $2}') \n"
            - "HOST_NAME=$(hostname) \n"
            - "SSH_SCRIPT_FILE=\"${ENV_DIR}/ssh.sh\" \n"
            - "NODES_INFO_FILE=\"${ENV_DIR}/nodes_info.ini\" \n"
            - "CLUSTER_FILE=\"${ENV_DIR}/cluster.sh\" \n"
            - "RM_NODES=\"${ENV_DIR}/rm_nodes.ini\" \n"
            - "rm -rf /etc/hosts && touch /etc/hosts \n"
            - " \n"
            - "recordLog() { \n"
            - "    time=$(date \"+%Y-%m-%d %H:%M:%S\") \n"
            - "    echo \"$time --- $1\" >>\"${ENV_DIR}/userdata.log\" \n"
            - "} \n"
            - " \n"
            - "createDir() { \n"
            - "    dir=$1 \n"
            - "    if [ -d \"${dir}\" ]; then \n"
            - "        recordLog \"Create failed, dir-${dir} is existed\" \n"
            - "    else \n"
            - "        mkdir -p \"${dir}\" \n"
            - "        recordLog \"Create Dir-${dir} successful\" \n"
            - "    fi \n"
            - "} \n"
            - " \n"
            - "delete() { \n"
            - "    rm -rf \"$1\" && recordLog \"Remove path-$1 successful\" \n"
            - "} \n"
            - " \n"
            - "download() { \n"
            - "    createDir ${RESOURCE_DIR} \n"
            - "    wget https://${OSS_NAME}.oss-${OSS_REGION}${ENDPOINT}/${OOS_JDK_FOLDER}/${JDK_RPM}\
              \ -P ${RESOURCE_DIR} \n"
            - "    wget https://${OSS_NAME}.oss-${OSS_REGION}${ENDPOINT}/${OOS_HADOOP_FOLDER}/${HADOOP_PACKAGE}\
              \ -P ${RESOURCE_DIR} \n"
            - "    recordLog \"Download resources successful\" \n"
            - "} \n"
            - " \n"
            - "generateScript() { \n"
            - "    ssh-keygen -t rsa -P '' -f '/root/.ssh/id_rsa' \n"
            - "    yum -y install expect \n"
            - "    echo '#!/bin/bash' >${SSH_SCRIPT_FILE} \n"
            - "    echo 'name_or_ip=$1' >>${SSH_SCRIPT_FILE} \n"
            - "    echo 'authorized_key=$2' >>${SSH_SCRIPT_FILE} \n"
            - "    echo 'expect <<EOF' >>${SSH_SCRIPT_FILE} \n"
            - "    echo 'set timeout 150' >>${SSH_SCRIPT_FILE} \n"
            - "    echo \"spawn ssh root@\\${name_or_ip} echo \\\"\\${authorized_key}\\\
              \" >> /root/.ssh/authorized_keys\" >>${SSH_SCRIPT_FILE} \n"
            - "    echo 'expect {' >>${SSH_SCRIPT_FILE} \n"
            - "    echo \"  \\\"*yes/no*\\\" { send \\\"yes\\n\\\"; exp_continue }\"\
              \ >>${SSH_SCRIPT_FILE} \n"
            - "    echo \"  \\\"*password:\\\" { send \\\"${PASSWORD}\\n\\\" }\" >>${SSH_SCRIPT_FILE}\
              \ \n"
            - "    echo '}' >>${SSH_SCRIPT_FILE} \n"
            - "    echo 'expect eof' >>${SSH_SCRIPT_FILE} \n"
            - "    echo 'EOF' >>${SSH_SCRIPT_FILE} \n"
            - "    chmod +x ${SSH_SCRIPT_FILE} \n"
            - "    recordLog \"Generate ${SSH_SCRIPT_FILE} successful\" \n"
            - "    echo '#!/bin/bash' >\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo 'host_ip=$1' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo 'expect <<EOF' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo 'set timeout 150' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo \"spawn ssh root@\\${host_ip} exit;\" >>\"${SSH_SCRIPT_FILE}.login\"\
              \ \n"
            - "    echo 'expect {' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo \"  \\\"*yes/no*\\\" { send \\\"yes\\n\\\" }\" >>\"${SSH_SCRIPT_FILE}.login\"\
              \ \n"
            - "    echo '}' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo 'expect eof' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    echo 'EOF' >>\"${SSH_SCRIPT_FILE}.login\" \n"
            - "    chmod +x \"${SSH_SCRIPT_FILE}.login\" \n"
            - "    recordLog \"Generate ${SSH_SCRIPT_FILE}.login successful\" \n"
            - "} \n"
            - " \n"
            - "configSSH() { \n"
            - "    authorized_key=$(cat /root/.ssh/id_rsa.pub) \n"
            - "    bash ${SSH_SCRIPT_FILE} \"${HOST_IP}\" \"${authorized_key}\" \n"
            - "    bash \"${SSH_SCRIPT_FILE}.login\" \"0.0.0.0\" \n"
            - "    bash \"${SSH_SCRIPT_FILE}.login\" \"localhost\" \n"
            - "    recordLog \"Config expect-localhost successful\" \n"
            - "} \n"
            - " \n"
            - "installJavaAndConfig() { \n"
            - "    yum -y install glibc.i686 \n"
            - "    cd ${RESOURCE_DIR} || exit && rpm -Uvh ${JDK_RPM} \n"
            - "    JAVA_HOME=$(find / -name jdk1.8.0_*) \n"
            - "    echo \"export JAVA_HOME=${JAVA_HOME}\" >>${BASH_PATH} \n"
            - "    echo \"export JRE_HOME=${JAVA_HOME}/jre\" >>${BASH_PATH} \n"
            - "    echo \"export CLASSPATH=.:${JAVA_HOME}/lib:${JAVA_HOME}/jre/lib\"\
              \ >>${BASH_PATH} \n"
            - "    echo \"export PATH=${JAVA_HOME}/bin:$PATH\" >>${BASH_PATH} \n"
            - "    source ${BASH_PATH} \n"
            - "    cd ~ || exit \n"
            - "    recordLog \"Install and config java env successful\" \n"
            - "    #    delete \"${RESOURCE_DIR}\\${JDK_RPM}\"  #do not delete \n"
            - "} \n"
            - " \n"
            - "installAndConfigHadoop() { \n"
            - "    cd ${RESOURCE_DIR} || exit && tar -zxvf \"${HADOOP_PACKAGE}\" -C\
              \ ${ENV_DIR} && cd ${ENV_DIR} && mv hadoop-2.7.7 hadoop \n"
            - "    echo \"export HADOOP_HOME=${HADOOP_HOME}\" >>${BASH_PATH} \n"
            - "    echo \"export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH\"\
              \ >>${BASH_PATH} \n"
            - "    source ${BASH_PATH} \n"
            - "    sed -i 's/export JAVA_HOME=/#export JAVA_HOME=/' ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh\
              \ \n"
            - "    sed -i \"/#export JAVA_HOME=/a export JAVA_HOME=${JAVA_HOME}\"\
              \ ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh \n"
            - "    cd ${HADOOP_HOME}/etc/hadoop/ || recordLog \"Enter hadoop\\etc\\\
              hadoop failed\" \n"
            - "    # config core-site.xml \n"
            - '    cat >core-site.xml <<EOF

              '
            - "<configuration> \n"
            - "  <property> \n"
            - "    <name>fs.defaultFS</name> \n"
            - "    <value>hdfs://HOST_NAME:9000</value> \n"
            - "    <description>HDFS URI</description> \n"
            - "  </property> \n"
            - "  <property> \n"
            - "    <name>hadoop.tmp.dir</name> \n"
            - "    <value>TMP_DIR</value> \n"
            - "    <description>NameNode upload hadoop temp folder</description> \n"
            - "  </property> \n"
            - "  <property> \n"
            - "    <name>fs.checkpoint.period</name> \n"
            - "    <value>3600</value> \n"
            - "    <description>set backup log timeout</description> \n"
            - "  </property> \n"
            - "</configuration> \n"
            - 'EOF

              '
            - "    sed -i \"s/HOST_NAME/${HOST_NAME}/\" core-site.xml \n"
            - "    sed -i \"s#TMP_DIR#${ENV_DIR}/tmp#\" core-site.xml \n"
            - "    recordLog \"Config core-site.xml successful\" \n"
            - "    # config hdfs-site.xml \n"
            - '    cat >hdfs-site.xml <<EOF

              '
            - "<configuration> \n"
            - " <property> \n"
            - "   <name>dfs.replication</name> \n"
            - "   <value>NODE_COUNT</value> \n"
            - "   <description>Duplication count</description> \n"
            - " </property> \n"
            - " <property> \n"
            - "    <name>dfs.name.dir</name> \n"
            - "    <value>HADOOP_HOME/hdfs/name</value> \n"
            - "    <description>DataNode name space metadata dir</description> \n"
            - "  </property> \n"
            - " <property> \n"
            - "    <name>dfs.data.dir</name> \n"
            - "    <value>HADOOP_HOME/hdfs/data</value> \n"
            - "    <description>DataNode data dir location</description> \n"
            - " </property> \n"
            - "</configuration> \n"
            - 'EOF

              '
            - "    sed -i \"s#HADOOP_HOME#${HADOOP_HOME}#\" ${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "    recordLog \"Config hdfs-site.xml successful\" \n"
            - "    # config yarn-site.xml \n"
            - '    cat >yarn-site.xml <<EOF

              '
            - "<configuration> \n"
            - "    <property> \n"
            - "        <name>yarn.resourcemanager.hostname</name> \n"
            - "        <value>HOST_NAME</value> \n"
            - "    </property> \n"
            - "    <property> \n"
            - "        <name>yarn.nodemanager.aux-services</name> \n"
            - "        <value>mapreduce_shuffle</value> \n"
            - "    </property> \n"
            - "</configuration> \n"
            - 'EOF

              '
            - "    sed -i \"s#HOST_NAME#${HOST_NAME}#\" ${ENV_DIR}/hadoop/etc/hadoop/yarn-site.xml\
              \ \n"
            - "    recordLog \"Config yarn-site.xml successful\" \n"
            - "    mv ${ENV_DIR}/hadoop/etc/hadoop/slaves ${ENV_DIR}/hadoop/etc/hadoop/bak.slaves\
              \ \n"
            - "    touch ${ENV_DIR}/hadoop/etc/hadoop/slaves \n"
            - "    recordLog \"Remove slave config default config\" \n"
            - "    delete \"${RESOURCE_DIR}/${HADOOP_PACKAGE}\" \n"
            - "} \n"
            - " \n"
            - "generateClusterScript() { \n"
            - '    cat >${CLUSTER_FILE} <<EOF

              '
            - "#!/bin/sh \n"
            - "NODE_COUNT=\\$1 \n"
            - "HOSTS_PATH=\"/etc/hosts\" \n"
            - "ENV_DIR=\"/software\" \n"
            - "SSH_SCRIPT_FILE=\"\\${ENV_DIR}/ssh.sh\" \n"
            - "NODES_COUNT_FILE=\"\\${ENV_DIR}/nodes_count.ini\" \n"
            - "HOST_IP=`ifconfig eth0 | awk '/inet /{print \\$2}'` \n"
            - "NODES_INFO_FILE=\"\\${ENV_DIR}/nodes_info.ini\" \n"
            - "RM_NODES=\"\\${ENV_DIR}/rm_nodes.ini\" \n"
            - "OLD_NODE_COUNT=\"\\${ENV_DIR}/rm_nodes.ini\" \n"
            - " \n"
            - "configCluster() { \n"
            - "    rm -f \\${ENV_DIR}/hadoop/etc/hadoop/slaves \n"
            - "    yes|cp \\${HOSTS_PATH} \"\\${HOSTS_PATH}.bak\" \n"
            - "    nodes_info=\\$(cat \\${NODES_INFO_FILE}) \n"
            - "    for node_info in \\${nodes_info[@]}; do \n"
            - "        new_node_info=(\\${node_info//:/ }) \n"
            - "        node_ip=\\${new_node_info[0]} \n"
            - "        node_hostname=\\${new_node_info[1]} \n"
            - "        echo \"\\${node_hostname}\" >> \\${ENV_DIR}/hadoop/etc/hadoop/slaves\
              \ \n"
            - "        if [ -d \"\\${ENV_DIR}/hadoop.bak\" ]; then \n"
            - "            yes|cp \"\\${ENV_DIR}/hadoop/etc/hadoop/slaves\" \"\\${ENV_DIR}/hadoop.bak/etc/hadoop/slaves\"\
              \ \n"
            - "        fi \n"
            - "        old_node_count=0 \n"
            - "        if [ \\${NODE_COUNT} -ge \\${old_node_count} ]; then \n"
            - "            grep \"\\${node_hostname}\" \"\\${HOSTS_PATH}.bak\" \n"
            - "            if [ \\$? -ne \"0\" ] ;then \n"
            - "                echo \"\\${node_ip} \\${node_hostname}\" >>\\${HOSTS_PATH}\
              \ \n"
            - "                authorized_key=\\$(cat /root/.ssh/id_rsa.pub) \n"
            - "                bash \\${SSH_SCRIPT_FILE} \"\\${node_hostname}\" \"\
              \\${authorized_key}\" \n"
            - "            fi \n"
            - "        fi \n"
            - "    done \n"
            - " \n"
            - "    if [ -f \\${NODES_COUNT_FILE} ]; then \n"
            - "        old_node_count=\\$(cat \\${NODES_COUNT_FILE}) \n"
            - "        sed -i \"s/\\${old_node_count}/\\${NODE_COUNT}/\" \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "        sed -i \"s/\\${old_node_count}/\\${NODE_COUNT}/\" \\${ENV_DIR}/hadoop.bak/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "        if [ \\${NODE_COUNT} -gt \\${old_node_count} ]; then \n"
            - "            echo \"add\" \n"
            - "            if [ ! -f \"\\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts\"\
              \ ] ;then \n"
            - "                sed -i \"\\|</configuration>|d\" \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \" <property>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \"    <name>dfs.hosts</name>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \"    <value>\\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts</value>\"\
              \ >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml \n"
            - "                echo \" </property>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \"</configuration>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "            fi \n"
            - "            rm -f \\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts \n"
            - "            yes|cp \\${ENV_DIR}/hadoop/etc/hadoop/slaves \\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts\
              \ \n"
            - "            nodes_info=\\$(cat \\${NODES_INFO_FILE}) \n"
            - "            for node_info in \\${nodes_info[@]}; do \n"
            - "                new_node_info=(\\${node_info//:/ }) \n"
            - "                node_ip=\\${new_node_info[0]} \n"
            - "                node_hostname=\\${new_node_info[1]} \n"
            - "                scp \\${HOSTS_PATH} root@\\${node_hostname}:/etc/ \n"
            - "                grep \"\\${node_hostname}\" \"\\${HOSTS_PATH}.bak\"\
              \ \n"
            - "                if [ \\$? -ne \"0\" ] ;then \n"
            - "                    scp -r \\${ENV_DIR}/hadoop.bak root@\\${node_hostname}:\\\
              ${ENV_DIR}/hadoop \n"
            - "                fi \n"
            - "            done \n"
            - "        else \n"
            - "            echo \"remove\" \n"
            - "            if [ ! -f \"\\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts.exclude\"\
              \ ] ;then \n"
            - "                sed -i \"\\|</configuration>|d\" \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \" <property>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \"    <name>dfs.hosts.exclude</name>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \"    <value>\\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts.exclude</value>\"\
              \ >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml \n"
            - "                echo \" </property>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "                echo \"</configuration>\" >> \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "            fi \n"
            - "            mv \\${RM_NODES} \\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts.exclude\
              \ \n"
            - "            if [ -f \"\\${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts\" ];\
              \ then \n"
            - "                rm_nodes_info=\\$(cat \\${RM_NODES}) \n"
            - "                for rm_node_info in \\${rm_nodes_info[@]}; do \n"
            - "                    sed -i '/\\${rm_node_info}/d' ${ENV_DIR}/hadoop/etc/hadoop/dfs.hosts\
              \ \n"
            - "                done \n"
            - "            fi \n"
            - "            nodes_info=\\$(cat \\${NODES_INFO_FILE}) \n"
            - "            for node_info in \\${nodes_info[@]}; do \n"
            - "                new_node_info=(\\${node_info//:/ }) \n"
            - "                node_ip=\\${new_node_info[0]} \n"
            - "                node_hostname=\\${new_node_info[1]} \n"
            - "                scp \\${ENV_DIR}/hadoop.bak/etc/hadoop/hdfs-site.xml\
              \ root@\\${node_hostname}:\\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "            done \n"
            - "        fi \n"
            - "    else \n"
            - "        sed -i \"s/NODE_COUNT/\\${NODE_COUNT}/\" \\${ENV_DIR}/hadoop/etc/hadoop/hdfs-site.xml\
              \ \n"
            - "        cp -rf \\${ENV_DIR}/hadoop /software/hadoop.bak \n"
            - "        for node_info in \\${nodes_info[@]}; do \n"
            - "            new_node_info=(\\${node_info//:/ }) \n"
            - "            node_ip=\\${new_node_info[0]} \n"
            - "            node_hostname=\\${new_node_info[1]} \n"
            - "            if [ \\${node_ip} -eq \\${HOST_IP} ]; then \n"
            - "                continue \n"
            - "            fi \n"
            - "            sleep 1 \n"
            - "            scp \\${HOSTS_PATH} root@\\${node_hostname}:/etc/ \n"
            - "            scp -r \\${ENV_DIR}/hadoop.bak root@\\${node_hostname}:\\\
              ${ENV_DIR}/hadoop \n"
            - "        done \n"
            - "    fi \n"
            - "} \n"
            - " \n"
            - "startCluster() { \n"
            - "    if [ -f \\${NODES_COUNT_FILE} ]; then \n"
            - "        old_node_count=\\$(cat \\${NODES_COUNT_FILE}) \n"
            - "        if [ \\${NODE_COUNT} -gt \\${old_node_count} ]; then \n"
            - "            cd \\${ENV_DIR}/hadoop && bin/hdfs dfsadmin -refreshNodes\
              \ \n"
            - "            bin/yarn rmadmin -refreshNodes && sbin/stop-yarn.sh &&\
              \ sbin/start-yarn.sh \n"
            - "            nodes_info=\\$(cat \\${NODES_INFO_FILE}) \n"
            - "            for node_info in \\${nodes_info[@]}; do \n"
            - "                new_node_info=(\\${node_info//:/ }) \n"
            - "                node_ip=\\${new_node_info[0]} \n"
            - "                node_hostname=\\${new_node_info[1]} \n"
            - "                grep \"\\${node_hostname}\" \"\\${HOSTS_PATH}.bak\"\
              \ \n"
            - "                if [ \\$? -ne \"0\" ] ;then \n"
            - "                    echo \\$node_hostname \n"
            - "                    ssh root@\\${node_hostname} \"cd \\${ENV_DIR}/hadoop\
              \ && sbin/hadoop-daemon.sh start datanode && sbin/yarn-daemon.sh start\
              \ nodemanager && exit;\" \n"
            - "                fi \n"
            - "            done \n"
            - "            cd \\${ENV_DIR}/hadoop && sbin/start-balancer.sh \n"
            - "        else \n"
            - "            echo \"remove\" \n"
            - "            cd \\${ENV_DIR}/hadoop && bin/hdfs dfsadmin -refreshNodes\
              \ && bin/yarn rmadmin -refreshNodes \n"
            - "            sleep 5 \n"
            - "            rm_nodes_info=\\$(cat \\${RM_NODES}) \n"
            - "            for rm_node in \\${rm_nodes_info[@]}; do \n"
            - "                ssh root@\\${rm_node} \"cd \\${ENV_DIR}/hadoop && sbin/hadoop-daemon.sh\
              \ stop datanode && sbin/yarn-daemon.sh stop nodemanager; sleep 5; exit;\"\
              \ \n"
            - "            done \n"
            - "            nodes_info=\\$(cat \\${NODES_INFO_FILE}) \n"
            - "            rm -f \\${HOSTS_PATH} \n"
            - "            for node_info in \\${nodes_info[@]}; do \n"
            - "                new_node_info=(\\${node_info//:/ }) \n"
            - "                node_ip=\\${new_node_info[0]} \n"
            - "                node_hostname=\\${new_node_info[1]} \n"
            - "                echo \"\\${node_ip} \\${node_hostname}\" >>\\${HOSTS_PATH}\
              \ \n"
            - "                echo \"\\${node_ip} \\${node_hostname}\" \n"
            - "                scp -r \"\\${HOSTS_PATH}\" \\${node_hostname}:/etc\
              \ \n"
            - "            done \n"
            - "            for node_info in \\${nodes_info[@]}; do \n"
            - "                new_node_info=(\\${node_info//:/ }) \n"
            - "                node_ip=\\${new_node_info[0]} \n"
            - "                node_hostname=\\${new_node_info[1]} \n"
            - "                scp -r \"\\${HOSTS_PATH}\" \\${node_hostname}:/etc\
              \ \n"
            - "            done \n"
            - "            sleep 10 \n"
            - "            cd \\${ENV_DIR}/hadoop/ && sbin/stop-dfs.sh && sbin/stop-yarn.sh\
              \ \n"
            - "            sbin/start-dfs.sh && bin/hdfs dfsadmin -refreshNodes \n"
            - "            sbin/start-yarn.sh && bin/yarn rmadmin -refreshNodes \n"
            - "            sbin/start-balancer.sh \n"
            - "        fi \n"
            - "    else \n"
            - "        cd \\${ENV_DIR}/hadoop/ && bin/hadoop namenode -format && sbin/start-dfs.sh\
              \ \n"
            - "        sbin/start-yarn.sh \n"
            - "    fi \n"
            - "    echo \\${NODE_COUNT} >\\${NODES_COUNT_FILE} \n"
            - "} \n"
            - " \n"
            - "main() { \n"
            - "    nodes_count=\\$(cat \\${NODES_INFO_FILE} | wc -l) \n"
            - "    nodes_info=\\$(cat \\${NODES_INFO_FILE}) \n"
            - "    if [ \\${nodes_count} -eq \\${NODE_COUNT} ]; then \n"
            - "        configCluster \n"
            - "        startCluster \n"
            - "        $ROS_NOTIFY \n"
            - "    fi \n"
            - "} \n"
            - " \n"
            - "main \n"
            - 'EOF

              '
            - "} \n"
            - " \n"
            - "main() { \n"
            - "    download \n"
            - "    generateScript \n"
            - "    configSSH \n"
            - "    installJavaAndConfig \n"
            - "    installAndConfigHadoop \n"
            - "    generateClusterScript \n"
            - "    echo \"${HOST_IP}:${HOST_NAME}\" >>${NODES_INFO_FILE} \n"
            - "    if [ -f ${RM_NODES} ]; then \n"
            - "        rm -f ${RM_NODES} \n"
            - "    fi \n"
            - "    touch ${RM_NODES} \n"
            - "} \n"
            - " \n"
            - "main \n"
            - "ros-notify -d \"{\\\"Status\\\" : \\\"Success\\\"}\" \n"
    DependsOn:
    - OOSTemplateIn
    Metadata:
      ALIYUN::ROS::Designer:
        id: 4d17593b-029a-45bf-849a-38376b2ac955
  VpcEip:
    Type: ALIYUN::VPC::EIP
    Properties:
      Bandwidth:
        Ref: BindWidth
      InternetChargeType: PayByTraffic
    Metadata:
      ALIYUN::ROS::Designer:
        id: c97c38d5-253b-4d8d-89f0-1537687b31b8
  EipAssociation:
    Type: ALIYUN::VPC::EIPAssociation
    Properties:
      InstanceId:
        Fn::Select:
        - '0'
        - Fn::GetAtt:
          - EcsInstanceGroupMaster
          - InstanceIds
      AllocationId:
        Ref: VpcEip
    DependsOn:
    - VpcEip
    Metadata:
      ALIYUN::ROS::Designer:
        id: fabc6711-b5c0-4aef-a1fc-fae3761b74a8
  OOSTemplateOut:
    Type: ALIYUN::OOS::Template
    Properties:
      Content:
        Fn::Join:
        - ''
        - - "FormatVersion: OOS-2019-06-01\nParameters:\n  regionId:\n    Type: String\n\
            \    Default: "
          - Ref: ALIYUN::Region
          - "\n  instanceIds:\n    Type: List\n    Default:\n      - '${instanceId}'\n\
            \  lifecycleHookId:\n    Type: String\n    Default: '${lifecycleHookId}'\n\
            \  lifecycleActionToken:\n    Type: String\n    Default: '${lifecycleActionToken}'\n\
            RamRole: "
          - Fn::GetAtt:
            - RamRole
            - RoleName
          - "\nTasks:\n  - Name: runCommand\n    Action: 'ACS::ECS::RunCommand'\n\
            \    OnError: CompleteLifecycleActionForAbandon\n    OnSuccess: CompleteLifecycleActionForContinue\n\
            \    Properties:\n      regionId: '{{ regionId }}'\n      commandContent:\
            \ |- \n"
          - Fn::Replace:
            - ros-notify:
                Fn::GetAtt:
                - RosWaitConditionHandleEss
                - CurlCli
            - Fn::Join:
              - ''
              - - "        #!/bin/sh \n"
                - "        hostname=$(hostname) \n"
                - '        MASTER_IP='
                - Fn::Select:
                  - '0'
                  - Fn::GetAtt:
                    - EcsInstanceGroupMaster
                    - PrivateIps
                - '

                  '
                - '        INSTANCE_PASSWORD='
                - Ref: InstancePassword
                - '

                  '
                - "        echo root:${INSTANCE_PASSWORD} | chpasswd \n"
                - "        # open sshd PasswordAuthentication \n"
                - "        sed -i 's/PasswordAuthentication no/PasswordAuthentication\
                  \ yes/g' \"/etc/ssh/sshd_config\" \n"
                - "        service sshd restart \n"
                - '        PASSWORD="'
                - Ref: InstancePassword
                - "\" \n"
                - '        NODE_COUNT='
                - Ref: Amount
                - '

                  '
                - '        MASTER_HOSTNAME='
                - Fn::Select:
                  - '0'
                  - Fn::GetAtt:
                    - EcsInstanceGroupMaster
                    - HostNames
                - '

                  '
                - "        set -e \n"
                - "        JDK_RPM=\"jdk-8u251-linux-i586.rpm\" \n"
                - "        ENV_DIR=\"/software\" \n"
                - "        BASH_PATH=\"/etc/profile\" \n"
                - "        RESOURCE_DIR=\"${ENV_DIR}/resources\" \n"
                - "        HOST_IP=$(ifconfig eth0 | awk '/inet /{print $2}') \n"
                - "        HOST_NAME=$(hostname) \n"
                - "        SSH_SCRIPT_FILE=\"/root/ssh.sh\" \n"
                - "        NODES_INFO_FILE=\"${ENV_DIR}/nodes_info.ini\" \n"
                - "        NODES_COUNT_FILE=\"${ENV_DIR}/nodes_count.ini\" \n"
                - "        CLUSTER_FILE=\"${ENV_DIR}/cluster.sh\" \n"
                - "        RM_NODE_FILE=\"${ENV_DIR}/rm_node.sh\" \n"
                - "        ADD_NODE_FILE=\"${ENV_DIR}/add_node.sh\" \n"
                - "        RM_NODES=\"${ENV_DIR}/rm_nodes.ini\" \n"
                - "         \n"
                - "        recordLog() { \n"
                - "            time=$(date \"+%Y-%m-%d %H:%M:%S\") \n"
                - "            if [ ! -d ${ENV_DIR} ]; then \n"
                - "                mkdir ${ENV_DIR} \n"
                - "            fi \n"
                - "            echo \"$time --- $1\" >>\"${ENV_DIR}/userdata.log\"\
                  \ \n"
                - "        } \n"
                - "         \n"
                - "        generateScript() { \n"
                - "            ssh-keygen -t rsa -P '' -f '/root/.ssh/id_rsa' \n"
                - "            yum -y install expect \n"
                - "            echo '#!/bin/bash' >${SSH_SCRIPT_FILE} \n"
                - "            echo 'name_or_ip=$1' >>${SSH_SCRIPT_FILE} \n"
                - "            echo 'authorized_key=$2' >>${SSH_SCRIPT_FILE} \n"
                - "            echo 'expect <<EOF' >>${SSH_SCRIPT_FILE} \n"
                - "            echo 'set timeout 150' >>${SSH_SCRIPT_FILE} \n"
                - "            echo \"spawn ssh root@\\${name_or_ip} echo \\\"\\${authorized_key}\\\
                  \" >> /root/.ssh/authorized_keys\" >>${SSH_SCRIPT_FILE} \n"
                - "            echo 'expect {' >>${SSH_SCRIPT_FILE} \n"
                - "            echo \"  \\\"*yes/no*\\\" { send \\\"yes\\n\\\"; exp_continue\
                  \ }\" >>${SSH_SCRIPT_FILE} \n"
                - "            echo \"  \\\"*password:\\\" { send \\\"${PASSWORD}\\\
                  n\\\" }\" >>${SSH_SCRIPT_FILE} \n"
                - "            echo '}' >>${SSH_SCRIPT_FILE} \n"
                - "            echo 'expect eof' >>${SSH_SCRIPT_FILE} \n"
                - "            echo 'EOF' >>${SSH_SCRIPT_FILE} \n"
                - "            chmod +x ${SSH_SCRIPT_FILE} \n"
                - "            recordLog \"Generate ${SSH_SCRIPT_FILE} successful\"\
                  \ \n"
                - "            echo '#!/bin/bash' >\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            echo 'host_ip=$1' >>\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            echo 'expect <<EOF' >>\"${SSH_SCRIPT_FILE}.login\"\
                  \ \n"
                - "            echo 'set timeout 150' >>\"${SSH_SCRIPT_FILE}.login\"\
                  \ \n"
                - "            echo \"spawn ssh root@\\${host_ip} exit;\" >>\"${SSH_SCRIPT_FILE}.login\"\
                  \ \n"
                - "            echo 'expect {' >>\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            echo \"  \\\"*yes/no*\\\" { send \\\"yes\\n\\\" }\"\
                  \ >>\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            echo '}' >>\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            echo 'expect eof' >>\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            echo 'EOF' >>\"${SSH_SCRIPT_FILE}.login\" \n"
                - "            chmod +x \"${SSH_SCRIPT_FILE}.login\" \n"
                - "            recordLog \"Generate ${SSH_SCRIPT_FILE}.login successful\"\
                  \ \n"
                - "        } \n"
                - "         \n"
                - "        configSSH() { \n"
                - "            authorized_key=$(cat /root/.ssh/id_rsa.pub) \n"
                - "            bash ${SSH_SCRIPT_FILE} \"${MASTER_IP}\" \"${authorized_key}\"\
                  \ \n"
                - "            bash ${SSH_SCRIPT_FILE} \"${HOST_IP}\" \"${authorized_key}\"\
                  \ \n"
                - "            bash \"${SSH_SCRIPT_FILE}.login\" \"0.0.0.0\" \n"
                - "            bash \"${SSH_SCRIPT_FILE}.login\" \"localhost\" \n"
                - "            sed -i \"s/${MASTER_IP}/${MASTER_HOSTNAME},${MASTER_IP}/\"\
                  \ \"/root/.ssh/known_hosts\" \n"
                - "            recordLog \"Config expect-localhost successful\" \n"
                - "        } \n"
                - "         \n"
                - "        installJavaAndConfig() { \n"
                - "            scp root@${MASTER_IP}:${RESOURCE_DIR}/${JDK_RPM} ./\
                  \ \n"
                - "            yum -y install glibc.i686 \n"
                - "            sleep 5 \n"
                - "            rpm -Uvh ${JDK_RPM} \n"
                - "            # config \n"
                - "            JAVA_HOME=$(find / -name jdk1.8.0_*) \n"
                - "            echo \"export JAVA_HOME=${JAVA_HOME}\" >>${BASH_PATH}\
                  \ \n"
                - "            echo \"export JRE_HOME=${JAVA_HOME}/jre\" >>${BASH_PATH}\
                  \ \n"
                - "            echo \"export CLASSPATH=.:${JAVA_HOME}/lib:${JAVA_HOME}/jre/lib\"\
                  \ >>${BASH_PATH} \n"
                - "            echo \"export PATH=${JAVA_HOME}/bin:$PATH\" >>${BASH_PATH}\
                  \ \n"
                - "            source ${BASH_PATH} \n"
                - "            recordLog \"Install and config java env successful\"\
                  \ \n"
                - "            rm -rf \"${JDK_RPM}\" \n"
                - "            recordLog \"Delete java rpm successful\" \n"
                - "        } \n"
                - "         \n"
                - "        configHadoop() { \n"
                - "            echo \"export HADOOP_HOME=${ENV_DIR}/hadoop\" >>${BASH_PATH}\
                  \ \n"
                - "            echo \"export PATH=${JAVA_HOME}/bin:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin:$PATH\"\
                  \ >>${BASH_PATH} \n"
                - "            source ${BASH_PATH} \n"
                - "        } \n"
                - "         \n"
                - "        generateAddNodeScript() { \n"
                - "            echo '#!/bin/bash' >${ADD_NODE_FILE} \n"
                - "            echo 'NODE_COUNT=$1' >>${ADD_NODE_FILE} \n"
                - "            echo \"ssh root@${MASTER_IP} \\\"echo '${HOST_IP}:${HOST_NAME}'\
                  \ >> ${NODES_INFO_FILE};bash ${CLUSTER_FILE} \\${NODE_COUNT} >>\
                  \ ${ENV_DIR}/userdata.log\\\"\" >>${ADD_NODE_FILE} \n"
                - "            echo \"ros-notify\" >> ${ADD_NODE_FILE}  \n"
                - "        } \n"
                - "         \n"
                - "        generateRmNodeScript() { \n"
                - "            echo '#!/bin/bash' >${RM_NODE_FILE} \n"
                - "            echo 'NODE_COUNT=$1' >>${RM_NODE_FILE} \n"
                - "            echo \"ssh root@${MASTER_IP} \\\"sed -i '/${HOST_IP}:${HOST_NAME}/d'\
                  \ ${NODES_INFO_FILE} && echo \"${HOST_NAME}\" >> ${RM_NODES} &&\
                  \ bash ${CLUSTER_FILE} \\${NODE_COUNT} >> ${ENV_DIR}/userdata.log;\
                  \ exit;\\\"\" >>${RM_NODE_FILE} \n"
                - "        } \n"
                - "         \n"
                - "        main() { \n"
                - "            generateScript \n"
                - "            configSSH \n"
                - "            installJavaAndConfig \n"
                - "            configHadoop \n"
                - "            generateRmNodeScript \n"
                - "            generateAddNodeScript \n"
                - "            bash ${ADD_NODE_FILE} ${NODE_COUNT} \n"
                - "        } \n"
                - "         \n"
                - "        main \n"
          - |2-

                  instanceId: '{{ ACS::TaskLoopItem }}'
                  commandType: RunShellScript
                Loop:
                  RateControl:
                    Mode: Concurrency
                    MaxErrors: 0
                    Concurrency: 10
                  Items: '{{ instanceIds }}'
                  Outputs:
                    commandOutputs:
                      AggregateType: 'Fn::ListJoin'
                      AggregateField: commandOutput
                Outputs:
                  commandOutput:
                    Type: String
                    ValueSelector: invocationOutput
              - Name: CompleteLifecycleActionForContinue
                Action: 'ACS::ExecuteAPI'
                OnSuccess: 'ACS::END'
                Properties:
                  Service: ESS
                  API: CompleteLifecycleAction
                  Parameters:
                    RegionId: '{{ regionId }}'
                    LifecycleHookId: '{{ lifecycleHookId }}'
                    LifecycleActionToken: '{{ lifecycleActionToken }}'
              - Name: CompleteLifecycleActionForAbandon
                Action: 'ACS::ExecuteAPI'
                Properties:
                  Service: ESS
                  API: CompleteLifecycleAction
                  Parameters:
                    RegionId: '{{ regionId }}'
                    LifecycleHookId: '{{ lifecycleHookId }}'
                    LifecycleActionToken: '{{ lifecycleActionToken }}'
                    LifecycleActionResult: ABANDON
      TemplateName:
        Fn::Join:
        - ''
        - - StackId-
          - Ref: ALIYUN::StackId
          - -Out
    DependsOn:
    - RamRole
    Metadata:
      ALIYUN::ROS::Designer:
        id: 67a74071-cd8a-4cf0-93bf-e4f05fbf4f7c
  RosWaitConditionMasterHandle:
    Type: ALIYUN::ROS::WaitConditionHandle
    Properties: {}
    Metadata:
      ALIYUN::ROS::Designer:
        id: 28c8b447-0074-4e1c-b16e-a23b999b1221
  RosWaitConditionMaster:
    Type: ALIYUN::ROS::WaitCondition
    Properties:
      Count: 1
      Handle:
        Ref: RosWaitConditionMasterHandle
      Timeout: 1800
    Metadata:
      ALIYUN::ROS::Designer:
        id: d31fecba-ebcf-42a2-b524-af819d7cc0fd
  EssScalingGroupSlave:
    Type: ALIYUN::ESS::ScalingGroup
    Properties:
      VSwitchId:
        Ref: VSwitchId
      DefaultCooldown: 0
      DesiredCapacity:
        Fn::Calculate:
        - '{0}-1'
        - 0
        - - Ref: Amount
      HealthCheckType: ECS
      MaxSize:
        Ref: Amount
      MinSize: 2
      RemovalPolicys:
      - NewestInstance
      - OldestScalingConfiguration
      ScalingGroupName:
        Fn::Join:
        - '-'
        - - StackId
          - Ref: ALIYUN::StackId
    DependsOn:
    - EcsInstanceGroupMaster
    - OOSTemplateIn
    - OOSTemplateOut
    - RosWaitConditionMaster
    Metadata:
      ALIYUN::ROS::Designer:
        id: c5ebe395-2e00-4f5c-9656-4db3c6a06f6d
  EssLifecycleHookIn:
    Type: ALIYUN::ESS::LifecycleHook
    Properties:
      DefaultResult: CONTINUE
      HeartbeatTimeout: 600
      LifecycleTransition: SCALE_IN
      NotificationArn:
        Fn::Join:
        - ''
        - - 'acs:ess:'
          - Ref: ALIYUN::Region
          - ':'
          - Ref: ALIYUN::TenantId
          - :oos/
          - Fn::GetAtt:
            - OOSTemplateIn
            - TemplateName
      NotificationMetadata:
        Fn::Join:
        - ''
        - - '{"regionId": "${regionId}","instanceIds": "${instanceIds}","lifecycleHookId":
            "${lifecycleHookId}","lifecycleActionToken": "${lifecycleActionToken}"}'
      ScalingGroupId:
        Ref: EssScalingGroupSlave
    DependsOn:
    - EssScalingGroupSlave
    - OOSTemplateIn
    Metadata:
      ALIYUN::ROS::Designer:
        id: 3c848940-437b-4576-96e0-4514bedb2d90
  EssLifecycleHookOut:
    Type: ALIYUN::ESS::LifecycleHook
    Properties:
      DefaultResult: CONTINUE
      HeartbeatTimeout: 600
      LifecycleTransition: SCALE_OUT
      NotificationArn:
        Fn::Join:
        - ''
        - - 'acs:ess:'
          - Ref: ALIYUN::Region
          - ':'
          - Ref: ALIYUN::TenantId
          - :oos/
          - Fn::GetAtt:
            - OOSTemplateOut
            - TemplateName
      NotificationMetadata:
        Fn::Join:
        - ''
        - - '{"regionId": "${regionId}","instanceIds": "${instanceIds}","lifecycleHookId":
            "${lifecycleHookId}","lifecycleActionToken": "${lifecycleActionToken}"}'
      ScalingGroupId:
        Ref: EssScalingGroupSlave
    DependsOn:
    - EssScalingGroupSlave
    - OOSTemplateOut
    Metadata:
      ALIYUN::ROS::Designer:
        id: 6163867a-1838-4f86-bb06-ca736e88eb68
  EssScalingConfigurationSlave:
    Type: ALIYUN::ESS::ScalingConfiguration
    Properties:
      SecurityGroupId:
        Ref: SecurityGroupId
      ImageId: centos_7_06_64_20G_alibase_20190711.vhd
      InstanceName:
        Fn::Join:
        - '-'
        - - YARN-node
          - Ref: ALIYUN::StackId
      InstanceTypes:
      - Ref: InstanceType
      IoOptimized: optimized
      ScalingGroupId:
        Ref: EssScalingGroupSlave
      SystemDiskCategory:
        Ref: DiskCategory
      SystemDiskSize:
        Ref: DiskSize
    DependsOn:
    - EssScalingGroupSlave
    Metadata:
      ALIYUN::ROS::Designer:
        id: 440cd165-f824-4c69-8005-2ba8b4bfbe47
  EssScalingGroupEnable:
    Type: ALIYUN::ESS::ScalingGroupEnable
    Properties:
      ScalingConfigurationId:
        Ref: EssScalingConfigurationSlave
      ScalingGroupId:
        Ref: EssScalingGroupSlave
    DependsOn:
    - EssScalingConfigurationSlave
    - EssScalingGroupSlave
    - RosWaitConditionMaster
    Metadata:
      ALIYUN::ROS::Designer:
        id: 866c1f6a-2b7a-49c3-be21-17c039d49eb4
  RosWaitConditionClusterHandle:
    Type: ALIYUN::ROS::WaitConditionHandle
    Properties: {}
    Metadata:
      ALIYUN::ROS::Designer:
        id: 96189890-7475-4a66-956e-0a7bf79f1832
  RosWaitConditionCluster:
    Type: ALIYUN::ROS::WaitCondition
    Properties:
      Count: 1
      Handle:
        Ref: RosWaitConditionClusterHandle
      Timeout: 3600
    Metadata:
      ALIYUN::ROS::Designer:
        id: ac2da7a5-324d-445d-b539-670f51aa4211
  RosWaitConditionHandleEss:
    Type: ALIYUN::ROS::WaitConditionHandle
    Properties: {}
    Metadata:
      ALIYUN::ROS::Designer:
        id: 7a568f88-588f-4635-b081-f327f41d685a
  RosWaitConditionEss:
    Type: ALIYUN::ROS::WaitCondition
    Properties:
      Count:
        Fn::Calculate:
        - '{0}-1'
        - 0
        - - Ref: Amount
      Handle:
        Ref: RosWaitConditionHandleEss
      Timeout: 1800
    Metadata:
      ALIYUN::ROS::Designer:
        id: aca6e39d-f458-420b-8506-9ca72010ea67
Outputs:
  EcsEip:
    Value:
      Fn::GetAtt:
      - VpcEip
      - EipAddress
  EcsInstanceIds:
    Value:
      Fn::GetAtt:
      - EcsInstanceGroupMaster
      - InstanceIds
  EssGroupId:
    Value:
      Fn::GetAtt:
      - EssScalingGroupSlave
      - ScalingGroupId
  HDFSManagerUrl:
    Value:
      Fn::Join:
      - ''
      - - http://
        - Fn::GetAtt:
          - VpcEip
          - EipAddress
        - :50070
  MasterPrivateIp:
    Value:
      Fn::Select:
      - '0'
      - Fn::GetAtt:
        - EcsInstanceGroupMaster
        - PrivateIps
  YARNWebUrl:
    Value:
      Fn::Join:
      - ''
      - - http://
        - Fn::GetAtt:
          - VpcEip
          - EipAddress
        - :8088
Metadata:
  ALIYUN::ROS::Interface:
    ParameterGroups:
    - Parameters:
      - VpcId
      - VSwitchZoneId
      - VSwitchId
      - SecurityGroupId
      Label:
        default:
          en: Infrastructure Configuration
          zh-cn: 基础资源配置（必填）
    - Parameters:
      - InstanceType
      - InstancePassword
      - BindWidth
      - DiskCategory
      - DiskSize
      - Amount
      Label:
        default:
          en: YARN Configuration
          zh-cn: YARN 配置（必填）
    TemplateTags:
    - acs:solution:数据分析:YARN集群版(已有VPC)
  ALIYUN::ROS::Designer:
    28c8b447-0074-4e1c-b16e-a23b999b1221:
      position:
        x: -177
        y: 125
      size:
        height: 60
        width: 60
      z: 0
    29aa811e-37bf-4487-b5a4-a0479d28f65b:
      source:
        id: f38f57e5-4fad-404f-9550-45331dca1d60
      target:
        id: c40eb24b-0042-4ad8-b85c-b6155fa52238
      z: 1
    3c848940-437b-4576-96e0-4514bedb2d90:
      position:
        x: -5
        y: 344
      size:
        height: 60
        width: 60
      z: 0
    440cd165-f824-4c69-8005-2ba8b4bfbe47:
      position:
        x: 85
        y: 23
      size:
        height: 60
        width: 60
      z: 0
    4d17593b-029a-45bf-849a-38376b2ac955:
      position:
        x: -227
        y: 202
      size:
        height: 60
        width: 60
      z: 0
    56eeaf99-c2dc-4fbc-83f1-cb8eebc74a54:
      source:
        id: 3c848940-437b-4576-96e0-4514bedb2d90
      target:
        id: f38f57e5-4fad-404f-9550-45331dca1d60
      z: 1
    6163867a-1838-4f86-bb06-ca736e88eb68:
      position:
        x: 184
        y: 344
      size:
        height: 60
        width: 60
      z: 0
    676fcf93-a391-4091-b275-fda3dde5e00f:
      source:
        id: 3c848940-437b-4576-96e0-4514bedb2d90
      target:
        id: c5ebe395-2e00-4f5c-9656-4db3c6a06f6d
      z: 1
    67a74071-cd8a-4cf0-93bf-e4f05fbf4f7c:
      position:
        x: 184
        y: 455
      size:
        height: 60
        width: 60
      z: 0
    6d165595-5940-4434-a9c1-f7f949a28319:
      source:
        id: aca6e39d-f458-420b-8506-9ca72010ea67
      target:
        id: 7a568f88-588f-4635-b081-f327f41d685a
      z: 1
    6fd03136-d325-45b4-a36e-35817e61bf55:
      source:
        id: 866c1f6a-2b7a-49c3-be21-17c039d49eb4
      target:
        id: 440cd165-f824-4c69-8005-2ba8b4bfbe47
      z: 1
    76a7a3dd-3fbd-49d9-b414-e3727db7ce8a:
      source:
        id: d31fecba-ebcf-42a2-b524-af819d7cc0fd
      target:
        id: 28c8b447-0074-4e1c-b16e-a23b999b1221
      z: 1
    7a568f88-588f-4635-b081-f327f41d685a:
      position:
        x: 245
        y: 216
      size:
        height: 60
        width: 60
      z: 0
    866c1f6a-2b7a-49c3-be21-17c039d49eb4:
      position:
        x: -61
        y: 106
      size:
        height: 60
        width: 60
      z: 0
    8798c069-8f51-492f-9f68-63daf0f63476:
      source:
        id: 866c1f6a-2b7a-49c3-be21-17c039d49eb4
      target:
        id: c5ebe395-2e00-4f5c-9656-4db3c6a06f6d
      z: 1
    96189890-7475-4a66-956e-0a7bf79f1832:
      position:
        x: -174
        y: 289
      size:
        height: 60
        width: 60
      z: 0
    a3eded63-ff54-4d86-8fd8-ca9cace28183:
      source:
        id: 440cd165-f824-4c69-8005-2ba8b4bfbe47
      target:
        id: c5ebe395-2e00-4f5c-9656-4db3c6a06f6d
      z: 1
    a82a948b-5ba6-4adb-94e8-34fe8db27c79:
      source:
        id: 6163867a-1838-4f86-bb06-ca736e88eb68
      target:
        id: c5ebe395-2e00-4f5c-9656-4db3c6a06f6d
      z: 1
    abf654b3-9590-4a77-9944-24093cf9b09f:
      source:
        id: fabc6711-b5c0-4aef-a1fc-fae3761b74a8
      target:
        id: 4d17593b-029a-45bf-849a-38376b2ac955
      z: 1
    ac2da7a5-324d-445d-b539-670f51aa4211:
      position:
        x: -344
        y: 289
      size:
        height: 60
        width: 60
      z: 0
    aca6e39d-f458-420b-8506-9ca72010ea67:
      position:
        x: 245
        y: 120
      size:
        height: 60
        width: 60
      z: 0
    b6236b25-2ebe-476e-8ac5-4966ebf40a81:
      source:
        id: ac2da7a5-324d-445d-b539-670f51aa4211
      target:
        id: 96189890-7475-4a66-956e-0a7bf79f1832
      z: 1
    b65e9c4a-0344-406a-8b71-02e0a5eb4a2e:
      source:
        id: 67a74071-cd8a-4cf0-93bf-e4f05fbf4f7c
      target:
        id: c40eb24b-0042-4ad8-b85c-b6155fa52238
      z: 1
    bfce6520-baca-42af-9a93-883f048d3f4c:
      source:
        id: fabc6711-b5c0-4aef-a1fc-fae3761b74a8
      target:
        id: c97c38d5-253b-4d8d-89f0-1537687b31b8
      z: 1
    c40eb24b-0042-4ad8-b85c-b6155fa52238:
      position:
        x: 90
        y: 565
      size:
        height: 60
        width: 60
      z: 0
    c5ebe395-2e00-4f5c-9656-4db3c6a06f6d:
      position:
        x: 85
        y: 188
      size:
        height: 60
        width: 60
      z: 0
    c97c38d5-253b-4d8d-89f0-1537687b31b8:
      position:
        x: -526
        y: 202
      size:
        height: 60
        width: 60
      z: 0
    d31fecba-ebcf-42a2-b524-af819d7cc0fd:
      position:
        x: -346
        y: 125
      size:
        height: 60
        width: 60
      z: 0
    e05dae61-c0f3-45fd-84e1-4b709d8a6da6:
      source:
        id: 6163867a-1838-4f86-bb06-ca736e88eb68
      target:
        id: 67a74071-cd8a-4cf0-93bf-e4f05fbf4f7c
      z: 1
    f38f57e5-4fad-404f-9550-45331dca1d60:
      position:
        x: -5
        y: 455
      size:
        height: 60
        width: 60
      z: 0
    fabc6711-b5c0-4aef-a1fc-fae3761b74a8:
      position:
        x: -377
        y: 202
      size:
        height: 60
        width: 60
      z: 0
